{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                            # to analyse data that are stored in a csv file\n",
    "import numpy as np                             # to provide a large set of numeric datatypes that can be used to construct arrays\n",
    "import nltk                                    # a platform for building Python programs to work with human language data\n",
    "from nltk.corpus import stopwords              # to remove stopwords\n",
    "from nltk.stem import WordNetLemmatizer        # to lemmatize\n",
    "from nltk.corpus import wordnet                # used to check whether the word is an adjective, noun, verb or adverb\n",
    "import re   # regex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('preprocessed_review.csv')\n",
    "dat['processed'] = np.nan\n",
    "dat = dat.drop(columns = ['Unnamed: 0'])      # drop unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"    \n",
    "    This function gets the wordnet postag of each words.\n",
    "    :param word: word in each review texts\n",
    "    :returns: the postag of each word \n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))     # define the stop words\n",
    "lemmatizer = WordNetLemmatizer()                 # define the lemmatizer\n",
    "def preprocess(review):\n",
    "    \"\"\"\n",
    "    This function takes in a list and preprocess accordingly. \n",
    "    :param review: list as input\n",
    "    :returns: preprocessed words\n",
    "    \"\"\"\n",
    "    result = re.sub(r'\\d+','', review)      # Remove numbers/ digits\n",
    "    result = re.sub(r'[^\\w\\s]','',result)   # Remove puntuations\n",
    "    val = result.lower()                    # Convert all the reviews to lowercase\n",
    "    new_list = []\n",
    "    for word in val.split():                # tokenize and stop words removal\n",
    "        if word not in stop_words:\n",
    "            new_list.append(word)\n",
    "    \n",
    "    return new_list\n",
    "    \n",
    "    \n",
    "def lemmatize_it(series_list):\n",
    "    \"\"\"\n",
    "    This function is to carry out lemmatization on the\n",
    "    tokenized review\n",
    "    :series_list: series object that contains token to be lemmatized\n",
    "    :returns: lemmatized word\n",
    "    \"\"\"\n",
    "    stem_it = []\n",
    "    for i in series_list:\n",
    "        lem = lemmatizer.lemmatize(i, get_wordnet_pos(i))    # lemmatize based on the POS tag\n",
    "        stem_it.append(lem)\n",
    "        \n",
    "    return stem_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part', 'magic', 'grow', 'boy', 'buy', 'give', 'new', 'hornby', 'catalogue', 'every', 'year', 'even', 'include', 'product', 'previous', 'year', 'ive', 'still', 'get', 'old', 'one', 'date', 'back', 'somewhere', 'day', 'catalogue', 'especially', 'informative', 'tell', 'vintage', 'roll', 'stock', 'useful', 'dedicate', 'railway', 'one', 'particular', 'era', 'train', 'company']\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing \n",
    "dat['processed'] = dat['review'].apply(preprocess)\n",
    "dat['processed'] = dat['processed'].apply(lemmatize_it)\n",
    "print(dat['processed'][0])    # to make sure the result is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28212, 28732)\n"
     ]
    }
   ],
   "source": [
    "# tf-idf using built-in function\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = dat['processed'].values\n",
    "Y_1 = dat['rating'].values\n",
    "\n",
    "def dummy_func(docs):\n",
    "    \"\"\"\n",
    "    Works as a dummy function as the name implies\n",
    "    \"\"\"\n",
    "    return docs\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_func, preprocessor=dummy_func, token_pattern=None)\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(vectorizer.fit_transform(X_1))    # do tfidf transformer after tfidf vectorizer\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in range(len(X_1))]\n",
    "rows, cols = X.nonzero()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train model with kfold cross-validation\n",
    "After getting the tfidf for each review, do kfold, undersample/ oversample\n",
    "and pass the result into the model for training\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold         # to perform kfold cross validation\n",
    "from imblearn.under_sampling import NearMiss                # to perform undersampling\n",
    "from imblearn.over_sampling import ADASYN                   # to perform oversampling\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score # score for evalution purposes\n",
    "from sklearn.neural_network import MLPClassifier            # to train with MLP classifier\n",
    "import time                                                 # to keep track of the time for program to execute\n",
    "from sklearn.svm import SVC, LinearSVC                      #to train support vector machine models\n",
    "from sklearn.multiclass import OneVsRestClassifier    #a multiclass strategy that fits one classifier per class\n",
    "from sklearn.feature_selection import SelectKBest     #a feature selection method\n",
    "from sklearn.feature_selection import chi2            #compute chi-squared stats between each non-negative feature and class\n",
    "from imblearn.pipeline import make_pipeline           #construct a pipeline from given estimators. Automates a machine learning workflow\n",
    "import datetime\n",
    "\n",
    "\n",
    "# list declaration\n",
    "Y = Y_1\n",
    "accuracy = []\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "f1_micro =[]\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "f1_macro =[]\n",
    "precision_weighted = []\n",
    "recall_weighted = []\n",
    "f1_weighted =[]\n",
    "\n",
    "def train_model(X, Y):\n",
    "    \"\"\"\n",
    "    We will be experimenting on Support Vector Machine and Multilayer Perceptron Neural Network \n",
    "    to determine which algorithm builds a better model. We will also perform both oversampling(ADASYN)\n",
    "    and undersampling (NearMiss) to determine which resampling method is more accurate. Besides that, \n",
    "    we will be using SelectKBest method to select features. We will be testing out OneVsRestClassifier\n",
    "    on SVC models to see whether it improves the accuracy and precision values. The usage of pipeline is\n",
    "    to ensure that the workflow is properly followed.\n",
    "    \n",
    "    Some lines of code for LinearSVC, SVC and MLP are commented out to prevent confusion. \n",
    "    To test out a specific line of code, comment out the current line of code and uncomment the you want to try.\n",
    "    To run the code without feature selection, remove SelectKBest() from the respective line of code.\n",
    "    \n",
    "    Some lines of code for LinearSVC, SVC and MLP are commented out to prevent confusion. \n",
    "    \n",
    "    :params X: the tfidf values to be trained\n",
    "    :params Y: the ratings to be trained\n",
    "    \"\"\"\n",
    "    # k fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        start_fold = datetime.datetime.now()\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        ''' SVC\n",
    "        For our research, we switched the kernel between 'rbf' and 'linear' with different numbers of features selected.\n",
    "        The first and second line of code performs oversampling whereas the third and fourth line of code performs undersampling.\n",
    "        The first and third line of code contains OneVsRestClassifier whereas the second and fourth line of code does not.\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        \n",
    "        ''' LinearSVC\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling.\n",
    "        The third line of code does not perform any feature selection.\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=25000),ADASYN(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        pipeline = make_pipeline(ADASYN(random_state=42),LinearSVC(C=1,random_state=42))\n",
    "        \n",
    "        ''' MLPClassifier\n",
    "        For our research, we switched the solver parameter between 'sgd' and 'adam' and tried different values of hidden_layer_sizes.\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        \n",
    "        #fit the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        #using testing data to predict the results\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        print(confusion_matrix(Y_test, y_pred))\n",
    "        print(classification_report(Y_test,y_pred))\n",
    "\n",
    "        #appends the results into respective lists\n",
    "        accuracy.append(accuracy_score(Y_test,y_pred))\n",
    "        #micro average\n",
    "        precision_micro.append(precision_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        recall_micro.append(recall_score(Y_test,y_pred,average='micro'))\n",
    "        f1_micro.append(f1_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        #macro average\n",
    "        precision_macro.append(precision_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        recall_macro.append(recall_score(Y_test,y_pred,average='macro'))\n",
    "        f1_macro.append(f1_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        #weighted average\n",
    "        precision_weighted.append(precision_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        recall_weighted.append(recall_score(Y_test,y_pred,average='weighted'))\n",
    "        f1_weighted.append(f1_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        \n",
    "        print(\"duration for this fold: \",datetime.datetime.now() - start_fold)\n",
    "        \n",
    "    # prints out the mean of the result from respective lists    \n",
    "    print(\"accuracy testing: {}\".format(np.mean(accuracy)))\n",
    "    print(\"precision_micro: {}\".format(np.mean(precision_micro)))\n",
    "    print(\"recall_micro: {}\".format(np.mean(recall_micro)))\n",
    "    print(\"f1_micro: {}\".format(np.mean(f1_micro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_macro: {}\".format(np.mean(precision_macro)))\n",
    "    print(\"recall_macro: {}\".format(np.mean(recall_macro)))\n",
    "    print(\"f1_macro: {}\".format(np.mean(f1_macro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_weighted: {}\".format(np.mean(precision_weighted)))\n",
    "    print(\"recall_weighted: {}\".format(np.mean(recall_weighted)))\n",
    "    print(\"f1_weighted: {}\".format(np.mean(f1_weighted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14    9   16   10   12]\n",
      " [   4    9   17    9   16]\n",
      " [   5   13   61   43   38]\n",
      " [   9   13   61  185  227]\n",
      " [  17   20  128  462 1425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.23      0.25        61\n",
      "           2       0.14      0.16      0.15        55\n",
      "           3       0.22      0.38      0.28       160\n",
      "           4       0.26      0.37      0.31       495\n",
      "           5       0.83      0.69      0.76      2052\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      2823\n",
      "   macro avg       0.35      0.37      0.35      2823\n",
      "weighted avg       0.67      0.60      0.63      2823\n",
      "\n",
      "duration for this fold:  0:00:41.301006\n",
      "[[  24    6   16    8    7]\n",
      " [  11    3   18   14    9]\n",
      " [  18    4   72   40   26]\n",
      " [  19   14   92  158  212]\n",
      " [  48   40  167  431 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.39      0.27        61\n",
      "           2       0.04      0.05      0.05        55\n",
      "           3       0.20      0.45      0.27       160\n",
      "           4       0.24      0.32      0.28       495\n",
      "           5       0.84      0.67      0.74      2052\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2823\n",
      "   macro avg       0.31      0.38      0.32      2823\n",
      "weighted avg       0.67      0.57      0.61      2823\n",
      "\n",
      "duration for this fold:  0:00:42.436099\n",
      "[[  17    6   16   13    9]\n",
      " [  10    6   13   10   16]\n",
      " [  14    9   46   46   45]\n",
      " [  15    8   73  154  245]\n",
      " [  31   30  129  461 1401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.28      0.23        61\n",
      "           2       0.10      0.11      0.11        55\n",
      "           3       0.17      0.29      0.21       160\n",
      "           4       0.23      0.31      0.26       495\n",
      "           5       0.82      0.68      0.74      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.30      0.33      0.31      2823\n",
      "weighted avg       0.65      0.58      0.61      2823\n",
      "\n",
      "duration for this fold:  0:00:43.427186\n",
      "[[  17    8   11   11   14]\n",
      " [   9    9   14   14    9]\n",
      " [   9   14   40   55   42]\n",
      " [  10   17   86  173  209]\n",
      " [  23   26  123  495 1385]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.28      0.26        61\n",
      "           2       0.12      0.16      0.14        55\n",
      "           3       0.15      0.25      0.18       160\n",
      "           4       0.23      0.35      0.28       495\n",
      "           5       0.83      0.67      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.32      0.34      0.32      2823\n",
      "weighted avg       0.66      0.58      0.61      2823\n",
      "\n",
      "duration for this fold:  0:00:47.053903\n",
      "[[  16    4   14   12   14]\n",
      " [  11    5   15   13   11]\n",
      " [  11   14   43   53   39]\n",
      " [   9    9   62  165  250]\n",
      " [  18   19   83  425 1507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.27      0.26        60\n",
      "           2       0.10      0.09      0.09        55\n",
      "           3       0.20      0.27      0.23       160\n",
      "           4       0.25      0.33      0.28       495\n",
      "           5       0.83      0.73      0.78      2052\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2822\n",
      "   macro avg       0.32      0.34      0.33      2822\n",
      "weighted avg       0.66      0.62      0.64      2822\n",
      "\n",
      "duration for this fold:  0:00:50.004358\n",
      "[[  13    8   10   21    8]\n",
      " [   5    3   16   17   14]\n",
      " [   8    9   48   51   44]\n",
      " [   6   17   60  169  243]\n",
      " [  15   18   83  554 1382]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.22      0.24        60\n",
      "           2       0.05      0.05      0.05        55\n",
      "           3       0.22      0.30      0.25       160\n",
      "           4       0.21      0.34      0.26       495\n",
      "           5       0.82      0.67      0.74      2052\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2822\n",
      "   macro avg       0.32      0.32      0.31      2822\n",
      "weighted avg       0.65      0.57      0.60      2822\n",
      "\n",
      "duration for this fold:  0:00:42.901502\n",
      "[[  20    8   12    7   13]\n",
      " [   9    5   18   12   11]\n",
      " [   6    8   43   53   50]\n",
      " [   7   19   77  160  232]\n",
      " [  20   18  113  488 1412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.33      0.33        60\n",
      "           2       0.09      0.09      0.09        55\n",
      "           3       0.16      0.27      0.20       160\n",
      "           4       0.22      0.32      0.26       495\n",
      "           5       0.82      0.69      0.75      2051\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2821\n",
      "   macro avg       0.32      0.34      0.33      2821\n",
      "weighted avg       0.65      0.58      0.61      2821\n",
      "\n",
      "duration for this fold:  0:00:39.728918\n",
      "[[  14    3   16   19    8]\n",
      " [  17    2   10   15   10]\n",
      " [   8    8   37   63   44]\n",
      " [   9   10   58  197  220]\n",
      " [  13   22  105  590 1321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.23      0.23        60\n",
      "           2       0.04      0.04      0.04        54\n",
      "           3       0.16      0.23      0.19       160\n",
      "           4       0.22      0.40      0.29       494\n",
      "           5       0.82      0.64      0.72      2051\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2819\n",
      "   macro avg       0.30      0.31      0.29      2819\n",
      "weighted avg       0.65      0.56      0.59      2819\n",
      "\n",
      "duration for this fold:  0:00:39.779648\n",
      "[[  19    9   11   11   10]\n",
      " [  10    6   14   12   12]\n",
      " [   7   16   43   53   40]\n",
      " [   8   13   62  175  236]\n",
      " [  14   11  115  535 1376]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.32      0.32        60\n",
      "           2       0.11      0.11      0.11        54\n",
      "           3       0.18      0.27      0.21       159\n",
      "           4       0.22      0.35      0.27       494\n",
      "           5       0.82      0.67      0.74      2051\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2818\n",
      "   macro avg       0.33      0.34      0.33      2818\n",
      "weighted avg       0.66      0.57      0.61      2818\n",
      "\n",
      "duration for this fold:  0:00:41.225315\n",
      "[[  21   12    6   13    8]\n",
      " [   5    3   12   20   14]\n",
      " [   9    5   51   56   38]\n",
      " [   5    6   55  177  251]\n",
      " [  14   19  123  472 1423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.35      0.37        60\n",
      "           2       0.07      0.06      0.06        54\n",
      "           3       0.21      0.32      0.25       159\n",
      "           4       0.24      0.36      0.29       494\n",
      "           5       0.82      0.69      0.75      2051\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2818\n",
      "   macro avg       0.34      0.36      0.34      2818\n",
      "weighted avg       0.66      0.59      0.62      2818\n",
      "\n",
      "duration for this fold:  0:00:39.119342\n",
      "accuracy testing: 0.5820553982946671\n",
      "precision_micro: 0.5820553982946671\n",
      "recall_micro: 0.5820553982946671\n",
      "f1_micro: 0.5820553982946671\n",
      "\n",
      "precision_macro: 0.32047357576096136\n",
      "recall_macro: 0.3428493796194842\n",
      "f1_macro: 0.3237336358394779\n",
      "\n",
      "precision_weighted: 0.6592161696499572\n",
      "recall_weighted: 0.5820553982946671\n",
      "f1_weighted: 0.6124581769952193\n"
     ]
    }
   ],
   "source": [
    "# To train the data\n",
    "train_model(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
