{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                            # to analyse data that are stored in a csv file\n",
    "import numpy as np                             # to provide a large set of numeric datatypes that can be used to construct arrays\n",
    "import nltk                                    # a platform for building Python programs to work with human language data\n",
    "from nltk.corpus import stopwords              # to remove stopwords\n",
    "from nltk.stem import WordNetLemmatizer        # to lemmatize\n",
    "from nltk.corpus import wordnet                # used to check whether the word is an adjective, noun, verb or adverb\n",
    "import re   # regex model\n",
    "import datetime                           #to take note of the start and end time of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('preprocessed_review.csv')\n",
    "dat['processed'] = np.nan\n",
    "dat = dat.drop(columns = ['Unnamed: 0'])      # drop unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"    \n",
    "    This function gets the wordnet postag of each words.\n",
    "    :param word: word in each review texts\n",
    "    :returns: the postag of each word \n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))     # define the stop words\n",
    "lemmatizer = WordNetLemmatizer()                 # define the lemmatizer\n",
    "def preprocess(review):\n",
    "    \"\"\"\n",
    "    This function takes in a series object and \n",
    "    preprocess accordingly. \n",
    "    :param review: series object\n",
    "    :returns: preprocessed words\n",
    "    \"\"\"\n",
    "    result = review.str.replace(r'\\d+', '')     # Remove numbers/ digits\n",
    "    result = result.str.replace(r'\\W', ' ')     # Remove puntuations\n",
    "    val = result.str.lower()                    # Convert all the reviews to lowercase \n",
    "    \n",
    "    return val.apply(lambda row: [word for word in row.split() if word not in stop_words])   # tokenize and stop words removal\n",
    "    \n",
    "    \n",
    "def lemmatize_it(series_list):\n",
    "    \"\"\"\n",
    "    This function is to carry out lemmatization on the\n",
    "    tokenized review\n",
    "    :series_list: series object that contains token to be lemmatized\n",
    "    :returns: lemmatized word\n",
    "    \"\"\"\n",
    "    stem_it = []\n",
    "    for i in series_list:\n",
    "        lem = lemmatizer.lemmatize(i, get_wordnet_pos(i))    # lemmatize based on the POS tag\n",
    "        stem_it.append(lem)\n",
    "        \n",
    "    return stem_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration for text preprocessing:  0:08:57.128001\n",
      "['part', 'magic', 'grow', 'boy', 'buy', 'give', 'new', 'hornby', 'catalogue', 'every', 'year', 'even', 'include', 'product', 'previous', 'year', 'still', 'get', 'old', 'one', 'date', 'back', 'somewhere', 'day', 'catalogue', 'especially', 'informative', 'tell', 'vintage', 'roll', 'stock', 'useful', 'dedicate', 'railway', 'one', 'particular', 'era', 'train', 'company']\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing \n",
    "start_text_preprocessing = datetime.datetime.now()\n",
    "dat['processed'] = preprocess(dat['review'])\n",
    "dat['processed'] = dat['processed'].apply(lemmatize_it)\n",
    "\n",
    "print(\"duration for text preprocessing: \",datetime.datetime.now() - start_text_preprocessing)\n",
    "print(dat['processed'][0])    # to make sure the result is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28212, 18905)\n"
     ]
    }
   ],
   "source": [
    "# tf-idf using built-in function\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = dat['processed'].values\n",
    "Y_1 = dat['rating'].values\n",
    "\n",
    "def dummy_func(docs):\n",
    "    \"\"\"\n",
    "    Works as a dummy function as the name implies\n",
    "    \"\"\"\n",
    "    return docs\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_func, preprocessor=dummy_func, token_pattern=None)\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(vectorizer.fit_transform(X_1))    # do tfidf transformer after tfidf vectorizer\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in range(len(X_1))]\n",
    "rows, cols = X.nonzero()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train model with kfold cross-validation\n",
    "After getting the tfidf for each review, do kfold, undersample/ oversample\n",
    "and pass the result into the model for training\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold         # to perform kfold cross validation\n",
    "from imblearn.under_sampling import NearMiss                # to perform undersampling\n",
    "from imblearn.over_sampling import ADASYN                   # to perform oversampling\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score # score for evalution purposes\n",
    "from sklearn.neural_network import MLPClassifier            # to train with MLP classifier\n",
    "import time                                                 # to keep track of the time for program to execute\n",
    "from sklearn.svm import SVC, LinearSVC                      #to train support vector machine models\n",
    "from sklearn.multiclass import OneVsRestClassifier    #a multiclass strategy that fits one classifier per class\n",
    "from sklearn.feature_selection import SelectKBest     #a feature selection method\n",
    "from sklearn.feature_selection import chi2            #compute chi-squared stats between each non-negative feature and class\n",
    "from imblearn.pipeline import make_pipeline           #construct a pipeline from given estimators. Automates a machine learning workflow\n",
    "\n",
    "\n",
    "# list declaration\n",
    "Y = Y_1\n",
    "accuracy = []\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "f1_micro =[]\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "f1_macro =[]\n",
    "precision_weighted = []\n",
    "recall_weighted = []\n",
    "f1_weighted =[]\n",
    "\n",
    "def train_model(X, Y):\n",
    "    \"\"\"\n",
    "    We will be experimenting on Support Vector Machine and Multilayer Perceptron Neural Network \n",
    "    to determine which algorithm builds a better model. We will also perform both oversampling(ADASYN)\n",
    "    and undersampling (NearMiss) to determine which resampling method is more accurate. Besides that, \n",
    "    we will be using SelectKBest method to select features. We will be testing out OneVsRestClassifier\n",
    "    on SVC models to see whether it improves the accuracy and precision values. The usage of pipeline is\n",
    "    to ensure that the workflow is properly followed.\n",
    "    \n",
    "    Some lines of code for LinearSVC, SVC and MLP are commented out to prevent confusion. \n",
    "    To test out a specific line of code, comment out the current line of code and uncomment the you want to try.\n",
    "    To run the code without feature selection, remove SelectKBest() from the respective line of code.\n",
    "    \n",
    "    Some lines of code for LinearSVC, SVC and MLP are commented out to prevent confusion. \n",
    "    \n",
    "    :params X: the tfidf values to be trained\n",
    "    :params Y: the ratings to be trained\n",
    "    \"\"\"\n",
    "    # k fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        start_fold = datetime.datetime.now()\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        ''' SVC\n",
    "        For our research, we switched the kernel between 'rbf' and 'linear' with different numbers of features selected.\n",
    "        The first and second line of code performs oversampling whereas the third and fourth line of code performs undersampling.\n",
    "        The first and third line of code contains OneVsRestClassifier whereas the second and fourth line of code does not.\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        \n",
    "        ''' LinearSVC\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling.\n",
    "        The third line of code does not perform any feature selection.\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        pipeline = make_pipeline(ADASYN(random_state=42),LinearSVC(C=1,random_state=42))\n",
    "        \n",
    "        ''' MLPClassifier\n",
    "        For our research, we switched the solver parameter between 'sgd' and 'adam' and tried different values of hidden_layer_sizes.\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),ADASYN(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=10000),NearMiss(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        \n",
    "        #fit the model\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "        #using testing data to predict the results\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        print(confusion_matrix(Y_test, y_pred))\n",
    "        print(classification_report(Y_test,y_pred))\n",
    "\n",
    "        #appends the results into respective lists\n",
    "        accuracy.append(accuracy_score(Y_test,y_pred))\n",
    "        #micro average\n",
    "        precision_micro.append(precision_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        recall_micro.append(recall_score(Y_test,y_pred,average='micro'))\n",
    "        f1_micro.append(f1_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        #macro average\n",
    "        precision_macro.append(precision_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        recall_macro.append(recall_score(Y_test,y_pred,average='macro'))\n",
    "        f1_macro.append(f1_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        #weighted average\n",
    "        precision_weighted.append(precision_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        recall_weighted.append(recall_score(Y_test,y_pred,average='weighted'))\n",
    "        f1_weighted.append(f1_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        \n",
    "        print(\"duration for this fold: \",datetime.datetime.now() - start_fold)\n",
    "        \n",
    "    # prints out the mean of the result from respective lists    \n",
    "    print(\"accuracy testing: {}\".format(np.mean(accuracy)))\n",
    "    print(\"precision_micro: {}\".format(np.mean(precision_micro)))\n",
    "    print(\"recall_micro: {}\".format(np.mean(recall_micro)))\n",
    "    print(\"f1_micro: {}\".format(np.mean(f1_micro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_macro: {}\".format(np.mean(precision_macro)))\n",
    "    print(\"recall_macro: {}\".format(np.mean(recall_macro)))\n",
    "    print(\"f1_macro: {}\".format(np.mean(f1_macro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_weighted: {}\".format(np.mean(precision_weighted)))\n",
    "    print(\"recall_weighted: {}\".format(np.mean(recall_weighted)))\n",
    "    print(\"f1_weighted: {}\".format(np.mean(f1_weighted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17    8   14    9   13]\n",
      " [   4    8   16   10   17]\n",
      " [   7   10   58   44   41]\n",
      " [   8   13   59  201  214]\n",
      " [  14   28  123  474 1413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.28      0.31        61\n",
      "           2       0.12      0.15      0.13        55\n",
      "           3       0.21      0.36      0.27       160\n",
      "           4       0.27      0.41      0.33       495\n",
      "           5       0.83      0.69      0.75      2052\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      2823\n",
      "   macro avg       0.36      0.38      0.36      2823\n",
      "weighted avg       0.67      0.60      0.63      2823\n",
      "\n",
      "duration for this fold:  0:00:46.863295\n",
      "[[  23    5   16    9    8]\n",
      " [  10    4   17   13   11]\n",
      " [  19    6   70   37   28]\n",
      " [  23   19   93  154  206]\n",
      " [  62   39  181  397 1373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.38      0.23        61\n",
      "           2       0.05      0.07      0.06        55\n",
      "           3       0.19      0.44      0.26       160\n",
      "           4       0.25      0.31      0.28       495\n",
      "           5       0.84      0.67      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.30      0.37      0.32      2823\n",
      "weighted avg       0.67      0.58      0.61      2823\n",
      "\n",
      "duration for this fold:  0:00:47.886275\n",
      "[[  15    9   13   12   12]\n",
      " [   7    7   13   15   13]\n",
      " [  14   10   48   51   37]\n",
      " [  15   12   80  152  236]\n",
      " [  39   30  125  448 1410]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.25      0.20        61\n",
      "           2       0.10      0.13      0.11        55\n",
      "           3       0.17      0.30      0.22       160\n",
      "           4       0.22      0.31      0.26       495\n",
      "           5       0.83      0.69      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.30      0.33      0.31      2823\n",
      "weighted avg       0.65      0.58      0.61      2823\n",
      "\n",
      "duration for this fold:  0:00:47.283922\n",
      "[[  16    8   12   10   15]\n",
      " [  11   13   13   11    7]\n",
      " [  13   17   35   56   39]\n",
      " [  10   18   90  177  200]\n",
      " [  27   44  136  452 1393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.26      0.23        61\n",
      "           2       0.13      0.24      0.17        55\n",
      "           3       0.12      0.22      0.16       160\n",
      "           4       0.25      0.36      0.29       495\n",
      "           5       0.84      0.68      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.31      0.35      0.32      2823\n",
      "weighted avg       0.67      0.58      0.62      2823\n",
      "\n",
      "duration for this fold:  0:00:47.422163\n",
      "[[  17    3   18   11   11]\n",
      " [  10    5   14   19    7]\n",
      " [  14   11   47   58   30]\n",
      " [   6    9   62  161  257]\n",
      " [  20   20  100  385 1527]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.28      0.27        60\n",
      "           2       0.10      0.09      0.10        55\n",
      "           3       0.20      0.29      0.23       160\n",
      "           4       0.25      0.33      0.29       495\n",
      "           5       0.83      0.74      0.79      2052\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2822\n",
      "   macro avg       0.33      0.35      0.33      2822\n",
      "weighted avg       0.67      0.62      0.64      2822\n",
      "\n",
      "duration for this fold:  0:00:48.193406\n",
      "[[  15    9    9   19    8]\n",
      " [   7    3   14   20   11]\n",
      " [   7   13   44   58   38]\n",
      " [   7   19   69  155  245]\n",
      " [  19   22  101  519 1391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.25      0.26        60\n",
      "           2       0.05      0.05      0.05        55\n",
      "           3       0.19      0.28      0.22       160\n",
      "           4       0.20      0.31      0.24       495\n",
      "           5       0.82      0.68      0.74      2052\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2822\n",
      "   macro avg       0.31      0.31      0.30      2822\n",
      "weighted avg       0.65      0.57      0.60      2822\n",
      "\n",
      "duration for this fold:  0:00:49.647629\n",
      "[[  19    9   15    8    9]\n",
      " [   9    7   18   11   10]\n",
      " [   6    9   41   54   50]\n",
      " [   8   17   80  152  238]\n",
      " [  20   26  129  473 1403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.32      0.31        60\n",
      "           2       0.10      0.13      0.11        55\n",
      "           3       0.14      0.26      0.19       160\n",
      "           4       0.22      0.31      0.25       495\n",
      "           5       0.82      0.68      0.75      2051\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2821\n",
      "   macro avg       0.32      0.34      0.32      2821\n",
      "weighted avg       0.65      0.57      0.61      2821\n",
      "\n",
      "duration for this fold:  0:00:47.257180\n",
      "[[  13    3   20   17    7]\n",
      " [  17    4   11   14    8]\n",
      " [   8    9   46   58   39]\n",
      " [  11   12   62  192  217]\n",
      " [  16   22  119  586 1308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.22      0.21        60\n",
      "           2       0.08      0.07      0.08        54\n",
      "           3       0.18      0.29      0.22       160\n",
      "           4       0.22      0.39      0.28       494\n",
      "           5       0.83      0.64      0.72      2051\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      2819\n",
      "   macro avg       0.30      0.32      0.30      2819\n",
      "weighted avg       0.66      0.55      0.59      2819\n",
      "\n",
      "duration for this fold:  0:00:47.046404\n",
      "[[  21   14   11   10    4]\n",
      " [   8    5   17   10   14]\n",
      " [   7   13   49   54   36]\n",
      " [   5   11   75  182  221]\n",
      " [  19   15  124  502 1391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.35      0.35        60\n",
      "           2       0.09      0.09      0.09        54\n",
      "           3       0.18      0.31      0.23       159\n",
      "           4       0.24      0.37      0.29       494\n",
      "           5       0.83      0.68      0.75      2051\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2818\n",
      "   macro avg       0.34      0.36      0.34      2818\n",
      "weighted avg       0.67      0.58      0.62      2818\n",
      "\n",
      "duration for this fold:  0:00:47.050159\n",
      "[[  20    6    8   17    9]\n",
      " [   6    5   14   19   10]\n",
      " [   9    8   48   57   37]\n",
      " [   6    8   65  170  245]\n",
      " [  17   23  114  462 1435]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.33      0.34        60\n",
      "           2       0.10      0.09      0.10        54\n",
      "           3       0.19      0.30      0.24       159\n",
      "           4       0.23      0.34      0.28       494\n",
      "           5       0.83      0.70      0.76      2051\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      2818\n",
      "   macro avg       0.34      0.35      0.34      2818\n",
      "weighted avg       0.66      0.60      0.62      2818\n",
      "\n",
      "duration for this fold:  0:00:47.020227\n",
      "accuracy testing: 0.5835445100871565\n",
      "precision_micro: 0.5835445100871565\n",
      "recall_micro: 0.5835445100871565\n",
      "f1_micro: 0.5835445100871565\n",
      "\n",
      "precision_macro: 0.3196672255592598\n",
      "recall_macro: 0.3468581907866766\n",
      "f1_macro: 0.32463605005288376\n",
      "\n",
      "precision_weighted: 0.6632257447312572\n",
      "recall_weighted: 0.5835445100871565\n",
      "f1_weighted: 0.6150707147121502\n",
      "duration of training:  0:07:55.703560\n"
     ]
    }
   ],
   "source": [
    "# To train the data\n",
    "start = datetime.datetime.now()\n",
    "train_model(X, Y)\n",
    "end = datetime.datetime.now()\n",
    "duration = end - start\n",
    "print(\"duration of training: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
