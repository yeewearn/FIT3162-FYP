{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import datetime\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from contractions import CONTRACTION_MAP\n",
    "# from stopwords import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(word):\n",
    "    \"\"\"\n",
    "    This function expands words such as I'll to I will.\n",
    "    :param word: a single review\n",
    "    :returns: the expanded words\n",
    "    \"\"\"\n",
    "    expanded = ' '.join([CONTRACTION_MAP[t] if t in CONTRACTION_MAP else t for t in word.split(\" \") ])\n",
    "    return expanded\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    This function gets the wordnet postag of each words.\n",
    "    :param word: word in each review texts\n",
    "    :returns: the postag of each word \n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"R\":wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "    \n",
    "def preprocessing_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocesses the review texts by performing contractions, removing numbers and\n",
    "    punctuations, make all the characters into lowercase, tokenization, lemmatization as well as removing stopwords.\n",
    "    :param text: a single text review\n",
    "    :returns: a list of preprocessed words\n",
    "    \"\"\"\n",
    "    #contractions\n",
    "    expanded_text=expand_contractions(text)\n",
    "    #remove numbers\n",
    "    numbers_removed = re.sub(r'\\d+','',expanded_text)\n",
    "    #remove punctuation\n",
    "    punct_removed = re.sub(r'[^\\w\\s]','',numbers_removed)\n",
    "    #tokenization\n",
    "    tokens = nltk.word_tokenize(punct_removed.lower())\n",
    "    \n",
    "    #remove stop words and lemmatization\n",
    "    lem_words = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in tokens:\n",
    "        temp_word = lemmatizer.lemmatize(word,get_wordnet_pos(word))\n",
    "        if  temp_word not in stop_words:\n",
    "            lem_words.append(temp_word)\n",
    "\n",
    "    return lem_words\n",
    "\n",
    "def calculate_tfidf(text):\n",
    "    def dummy_func(docs):\n",
    "        return docs\n",
    "    \n",
    "#     loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    transformer = TfidfTransformer()\n",
    "    loaded_vec = TfidfVectorizer(analyzer='word',tokenizer=dummy_func, preprocessor=dummy_func, token_pattern=None,vocabulary = pickle.load(open(\"feature.pkl\", \"rb\")))\n",
    "    tfidf = loaded_vec.fit_transform(text) \n",
    "    \n",
    "    return tfidf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28914)\n",
      "  (0, 25273)\t0.5773502691896258\n",
      "  (0, 8757)\t0.5773502691896258\n",
      "  (0, 4128)\t0.5773502691896258\n",
      "(1, 28914)\n",
      "  (0, 27060)\t0.4082482904638631\n",
      "  (0, 12781)\t0.4082482904638631\n",
      "  (0, 12337)\t0.4082482904638631\n",
      "  (0, 10544)\t0.4082482904638631\n",
      "  (0, 5845)\t0.4082482904638631\n",
      "  (0, 4587)\t0.4082482904638631\n",
      "(1, 28914)\n",
      "  (0, 27060)\t0.4082482904638631\n",
      "  (0, 12781)\t0.4082482904638631\n",
      "  (0, 12337)\t0.4082482904638631\n",
      "  (0, 10544)\t0.4082482904638631\n",
      "  (0, 5845)\t0.4082482904638631\n",
      "  (0, 4587)\t0.4082482904638631\n",
      "(1, 28914)\n",
      "  (0, 26376)\t0.21320071635561041\n",
      "  (0, 23787)\t0.42640143271122083\n",
      "  (0, 22832)\t0.42640143271122083\n",
      "  (0, 21163)\t0.21320071635561041\n",
      "  (0, 21129)\t0.21320071635561041\n",
      "  (0, 16479)\t0.21320071635561041\n",
      "  (0, 14534)\t0.21320071635561041\n",
      "  (0, 13084)\t0.42640143271122083\n",
      "  (0, 10463)\t0.21320071635561041\n",
      "  (0, 6638)\t0.21320071635561041\n",
      "  (0, 6529)\t0.21320071635561041\n",
      "  (0, 5495)\t0.21320071635561041\n",
      "  (0, 4988)\t0.21320071635561041\n",
      "(1, 28914)\n",
      "  (0, 23038)\t0.4472135954999579\n",
      "  (0, 22832)\t0.4472135954999579\n",
      "  (0, 21577)\t0.4472135954999579\n",
      "  (0, 14710)\t0.4472135954999579\n",
      "  (0, 4810)\t0.4472135954999579\n",
      "(1, 28914)\n",
      "  (0, 21196)\t0.17149858514250882\n",
      "  (0, 20930)\t0.17149858514250882\n",
      "  (0, 20530)\t0.17149858514250882\n",
      "  (0, 17438)\t0.5144957554275265\n",
      "  (0, 16563)\t0.17149858514250882\n",
      "  (0, 16445)\t0.5144957554275265\n",
      "  (0, 16413)\t0.17149858514250882\n",
      "  (0, 10934)\t0.17149858514250882\n",
      "  (0, 8541)\t0.17149858514250882\n",
      "  (0, 5670)\t0.17149858514250882\n",
      "  (0, 2556)\t0.34299717028501764\n",
      "  (0, 1697)\t0.34299717028501764\n",
      "(1, 28914)\n",
      "  (0, 22749)\t0.3779644730092272\n",
      "  (0, 20881)\t0.3779644730092272\n",
      "  (0, 20530)\t0.3779644730092272\n",
      "  (0, 17438)\t0.3779644730092272\n",
      "  (0, 15353)\t0.3779644730092272\n",
      "  (0, 2669)\t0.3779644730092272\n",
      "  (0, 2556)\t0.3779644730092272\n",
      "(1, 28914)\n",
      "  (0, 28400)\t0.2672612419124244\n",
      "  (0, 25306)\t0.2672612419124244\n",
      "  (0, 25273)\t0.2672612419124244\n",
      "  (0, 22832)\t0.2672612419124244\n",
      "  (0, 22586)\t0.2672612419124244\n",
      "  (0, 21424)\t0.2672612419124244\n",
      "  (0, 19062)\t0.2672612419124244\n",
      "  (0, 16145)\t0.2672612419124244\n",
      "  (0, 8757)\t0.2672612419124244\n",
      "  (0, 8701)\t0.2672612419124244\n",
      "  (0, 7422)\t0.2672612419124244\n",
      "  (0, 4587)\t0.2672612419124244\n",
      "  (0, 2905)\t0.2672612419124244\n",
      "  (0, 648)\t0.2672612419124244\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the basic user interface used to predict rating from a text review using Tkinter.\n",
    "'''\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import font\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "# import train_model\n",
    "\n",
    "        \n",
    "def reset():\n",
    "    '''\n",
    "    This function resets the review textbox and the predicted ratings textbox.\n",
    "    '''\n",
    "    textbox.delete(1.0,END)\n",
    "    result.config(state='normal')\n",
    "    result.delete(0,END)\n",
    "    result.config(state='disabled')\n",
    "\n",
    "    \n",
    "def predict():\n",
    "    '''\n",
    "    This function displays the predicted rating.\n",
    "    '''\n",
    "    result.config(state='normal')\n",
    "    result.delete(0,END)\n",
    "    \n",
    "    user_review = textbox.get(1.0,END) #gets the review text inputted by user\n",
    "    rev_list = []\n",
    "    Xx = preprocessing_text(user_review)\n",
    "    rev_list.append(Xx)\n",
    "    tfidf = calculate_tfidf(rev_list)\n",
    "    \n",
    "    loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
    "    prediction = loaded_model.predict(tfidf)\n",
    "    \n",
    "    result.insert(END,prediction)\n",
    "    result.config(state='disabled')\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "root.geometry(\"800x400\")    #Sets the size of window\n",
    "root.configure(background='#DEFFF0')   #Sets the background colour\n",
    "\n",
    "root.title('Ratings Prediction')  #Sets the title of the root\n",
    "\n",
    "#Displays the title\n",
    "main_title = Label(root,text=\"Ratings Prediction\",font=(\"Elephant\",30),bg='#DEFFF0')\n",
    "main_title.pack(fill=BOTH, expand=0)\n",
    "#To underline the main_title\n",
    "f = font.Font(main_title, main_title.cget(\"font\"))\n",
    "f.configure(underline=True)\n",
    "main_title.configure(font=f)\n",
    "\n",
    "#Displays text asking user to enter a review text\n",
    "text = Label(root, text=\"Enter a review text: \",font=(\"Times New Roman\",15),bg='#DEFFF0')\n",
    "text.pack(fill=BOTH, expand=0)\n",
    "\n",
    "#Displays the textbox where user will input the review text\n",
    "textbox=ScrolledText(root,height=5,width=40,font=(\"Times New Roman\",13))\n",
    "textbox.pack(fill=Y,expand=0)\n",
    "\n",
    "#Create a frame to put the buttons in\n",
    "frame = Frame(root, height=\"200\", width=\"200\", bg=\"#DEFFF0\",borderwidth = 13)\n",
    "frame.pack()\n",
    "\n",
    "#Create a button named \"Predict\" to predict the ratings\n",
    "pred_button = Button(frame,text=\"Predict\",font=(\"Times New Roman\",11),command = predict,bg='black',fg='white',height=2,width=10)\n",
    "pred_button.pack(padx=50, side=LEFT)\n",
    "\n",
    "#Create a button to clear the review text that user inputted\n",
    "clear_button = Button(frame,text=\"Clear Review Text\",font=(\"Times New Roman\",11),bg='black',fg='white',command=lambda: textbox.delete(1.0,END),height=2,width=20)\n",
    "clear_button.pack(padx=50,side=LEFT)\n",
    "\n",
    "#Create a button to reset the review text that user inputted as well as the displayed rating\n",
    "reset_button = Button(frame,text=\"Reset\",font=(\"Times New Roman\",11),command=reset,bg='black',fg='white',height=2,width=10)\n",
    "reset_button.pack(padx=50, side=LEFT)\n",
    "\n",
    "#Displays the text \n",
    "text2 = Label(root,text=\"The rating for this review is: \",font=(\"Times New Roman\",15),bg='#DEFFF0')\n",
    "text2.pack(padx=5,expand=0)\n",
    "  \n",
    "#Displays the predicted rating\n",
    "result = Entry(root,font=(\"Times New Roman\",13),bg='white')\n",
    "result.config(state='disabled',disabledbackground='white',disabledforeground='black',justify=CENTER)\n",
    "result.pack(fill=Y,expand=0)\n",
    "\n",
    "\n",
    "root.mainloop() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
