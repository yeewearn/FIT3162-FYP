{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import datetime\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from contractions import CONTRACTION_MAP\n",
    "from stopwords import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Read the csv file\n",
    "dat = pd.read_csv('review_ver2.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Change the display size\n",
    "pd.set_option('display.max_columns',20)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def expand_contractions(word):\n",
    "    \"\"\"\n",
    "    This function expands words such as I'll to I will.\n",
    "    :param word: a single review\n",
    "    :returns: the expanded words\n",
    "    \"\"\"\n",
    "    expanded = ' '.join([CONTRACTION_MAP[t] if t in CONTRACTION_MAP else t for t in word.split(\" \") ])\n",
    "    return expanded\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"\n",
    "    This function gets the wordnet postag of each words.\n",
    "    :param word: word in each review texts\n",
    "    :returns: the postag of each word \n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"R\":wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "    \n",
    "def preprocessing_text(text):\n",
    "    \"\"\"\n",
    "    This function preprocesses the review texts by performing contractions, removing numbers and\n",
    "    punctuations, make all the characters into lowercase, tokenization, lemmatization as well as removing stopwords.\n",
    "    :param text: a single text review\n",
    "    :returns: a list of preprocessed words\n",
    "    \"\"\"\n",
    "    #contractions\n",
    "    expanded_text=expand_contractions(text)\n",
    "    #remove numbers\n",
    "    numbers_removed = re.sub(r'\\d+','',expanded_text)\n",
    "    #remove punctuation\n",
    "    punct_removed = re.sub(r'[^\\w\\s]','',numbers_removed)\n",
    "    #tokenization\n",
    "    tokens = nltk.word_tokenize(punct_removed.lower())\n",
    "    \n",
    "    #remove stop words and lemmatization\n",
    "    lem_words = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in tokens:\n",
    "        temp_word = lemmatizer.lemmatize(word,get_wordnet_pos(word))\n",
    "        if  temp_word not in stop_words:\n",
    "            lem_words.append(temp_word)\n",
    "\n",
    "    return lem_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram(lem_words):\n",
    "    \"\"\"\n",
    "    This function gets the bigram of the review texts.\n",
    "    :param lem_words: a list of preprocessed words\n",
    "    :returns: a list of bigram words or just a single word (if unable to perform bigram)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(lem_words) <= 1: #the review contains a single word only, hence unable to perform bigram\n",
    "        return lem_words\n",
    "    \n",
    "    else:\n",
    "        #gets the bigram in the form of [('wordA','wordB'),('wordB,'wordC'),...]\n",
    "        bigrm = list(nltk.bigrams(lem_words))\n",
    "\n",
    "        #make the bigram in this format ['wordA wordB','wordB wordC',...]\n",
    "        bigrm_list = []\n",
    "        separator = ' '\n",
    "        for i in range(len(bigrm)):\n",
    "            bigrm_list.append(separator.join(bigrm[i]))   \n",
    "        return bigrm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration for text preprocessing:  0:15:28.856058\n",
      "duration for generating bigram:  0:00:00.617649\n"
     ]
    }
   ],
   "source": [
    "#applies the preprocessing_text function on all items in the review column\n",
    "start_text_preprocessing = datetime.datetime.now()\n",
    "lem_tokens = dat['review'].apply(preprocessing_text)\n",
    "print(\"duration for text preprocessing: \",datetime.datetime.now() - start_text_preprocessing)\n",
    "\n",
    "#applies the get_bigram function on all the items in the review column\n",
    "bigram_list = lem_tokens.apply(get_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  rating\n",
      "0  [part magic, magic grow, grow boy, boy buy, bu...       4\n",
      "1  [amaze detail, detail every, every credit, cre...       5\n",
      "2  [purchase behalf, behalf dad, dad always, alwa...       5\n",
      "3  [everything really, really need, need see, see...       5\n",
      "4  [collect glossy, glossy picture, picture great...       5\n",
      "5  [great book, book extremely, extremely useful,...       5\n",
      "6  [useful info, info someonelike, someonelike st...       5\n",
      "7  [well produce, produce good, good quality, qua...       5\n",
      "8     [happy communication, communication funkybuys]       4\n",
      "9                                        [great buy]       5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_rating(rates,bigram):\n",
    "    \"\"\"\n",
    "    This function ensures that all the ratings are integers.\n",
    "    :param rates: a list of ratings\n",
    "    :param bigram: list of bigram words\n",
    "    :returns: a new list of ratings and bigram words\n",
    "    \"\"\"\n",
    "    new_bigram = []\n",
    "    new_rating = []\n",
    "    \n",
    "    for i in range(len(rates)):\n",
    "        try:\n",
    "            new_rating.append(int(rates[i]))\n",
    "            new_bigram.append(bigram[i])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return new_bigram, new_rating\n",
    "\n",
    "\n",
    "rate_list=dat['rating'].values.tolist()\n",
    "new_bigram, new_rating = check_rating(rate_list,bigram_list)\n",
    "\n",
    "\n",
    "#putting the series of review texts into data frame\n",
    "df_bigram = pd.DataFrame({'review':new_bigram})\n",
    "df_rate = pd.DataFrame({'rating':new_rating})\n",
    "#concatenating the new data frame with ratings column\n",
    "result = pd.concat([df_bigram,df_rate],axis=1)\n",
    "print(result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the vextorizer:  (28212, 288098)\n"
     ]
    }
   ],
   "source": [
    "#Calculating the tf-idf values\n",
    "\n",
    "X_train_1 = result['review'].values\n",
    "Y_train_1 = result['rating'].values\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Just a dummy function.\n",
    "    \"\"\"\n",
    "    return text\n",
    "\n",
    "tfidf_1 = TfidfVectorizer(tokenizer=identity_tokenizer, analyzer='word',preprocessor = identity_tokenizer,lowercase=True)    \n",
    "X_1 = tfidf_1.fit_transform(X_train_1)\n",
    "\n",
    "print(\"shape of the vectorizer: \",X_1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling methods\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "def oversampling(X_train,y_train):\n",
    "    \"\"\"\n",
    "    This function performs oversampling using ADASYN.\n",
    "    :params X_train: the tfidf values to be trained\n",
    "    :params y_train: the ratings to be trained\n",
    "    :returns: the oversampled X_train and y_train data\n",
    "    \"\"\"\n",
    "    ada = ADASYN()\n",
    "    X_train_smt,y_train_smt = ada.fit_sample(X_train,y_train)\n",
    "    return X_train_smt,y_train_smt\n",
    "\n",
    "def undersampling(X_train,y_train):\n",
    "    \"\"\"\n",
    "    This function performs undersampling using NearMiss.\n",
    "    :params X_train: the tfidf values to be trained\n",
    "    :params y_train: the ratings to be trained\n",
    "    :returns: the undersampled X_train and y_train data\n",
    "    \"\"\"\n",
    "    nr = NearMiss()\n",
    "    X_train_nr,y_train_nr = nr.fit_sample(X_train,y_train)\n",
    "    return X_train_nr,y_train_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot graph to show top 10 features associated with respective ratings\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_coefficients(classifier, feature_names, top_features=10):\n",
    "#     coef = classifier.coef_\n",
    "#     print(coef)\n",
    "#     for i in range(len(coef)):\n",
    "#         top_positive_coefficients = np.argsort(coef[i])[-top_features:]\n",
    "#         # create plot\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "#         colors = ['red' if c < 0 else 'blue' for c in coef[i][top_positive_coefficients]]\n",
    "#         plt.bar(np.arange(2 * top_features), coef[i][top_positive_coefficients], color=colors)\n",
    "#         feature_names = np.array(feature_names)\n",
    "#         plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_positive_coefficients], rotation=60, ha='right')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5    0    4   16   36]\n",
      " [   1    1    5   22   26]\n",
      " [   0    0   16   65   79]\n",
      " [   0    0    8  178  309]\n",
      " [   0    1   25  329 1697]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.08      0.15        61\n",
      "           2       0.50      0.02      0.04        55\n",
      "           3       0.28      0.10      0.15       160\n",
      "           4       0.29      0.36      0.32       495\n",
      "           5       0.79      0.83      0.81      2052\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      2823\n",
      "   macro avg       0.54      0.28      0.29      2823\n",
      "weighted avg       0.67      0.67      0.66      2823\n",
      "\n",
      "duration of this fold:  0:00:56.064191\n",
      "[[   6    0    2   22   31]\n",
      " [   0    0    3   28   24]\n",
      " [   0    0   15   58   87]\n",
      " [   0    0   19  156  320]\n",
      " [   1    1   33  281 1736]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.10      0.18        61\n",
      "           2       0.00      0.00      0.00        55\n",
      "           3       0.21      0.09      0.13       160\n",
      "           4       0.29      0.32      0.30       495\n",
      "           5       0.79      0.85      0.82      2052\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2823\n",
      "   macro avg       0.43      0.27      0.28      2823\n",
      "weighted avg       0.65      0.68      0.66      2823\n",
      "\n",
      "duration of this fold:  0:01:00.538534\n",
      "[[   7    1    3   20   30]\n",
      " [   0    2    2   24   27]\n",
      " [   1    0    5   66   88]\n",
      " [   0    0   11  156  328]\n",
      " [   0    1    8  333 1710]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.11      0.20        61\n",
      "           2       0.50      0.04      0.07        55\n",
      "           3       0.17      0.03      0.05       160\n",
      "           4       0.26      0.32      0.29       495\n",
      "           5       0.78      0.83      0.81      2052\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      2823\n",
      "   macro avg       0.52      0.27      0.28      2823\n",
      "weighted avg       0.65      0.67      0.65      2823\n",
      "\n",
      "duration of this fold:  0:00:48.454299\n",
      "[[   3    0    1   15   42]\n",
      " [   1    1    2   20   31]\n",
      " [   2    0    9   54   95]\n",
      " [   0    0    2  145  348]\n",
      " [   1    0   22  258 1771]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.05      0.09        61\n",
      "           2       1.00      0.02      0.04        55\n",
      "           3       0.25      0.06      0.09       160\n",
      "           4       0.29      0.29      0.29       495\n",
      "           5       0.77      0.86      0.82      2052\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2823\n",
      "   macro avg       0.55      0.26      0.27      2823\n",
      "weighted avg       0.66      0.68      0.65      2823\n",
      "\n",
      "duration of this fold:  0:00:47.190040\n",
      "[[   2    0    4   18   36]\n",
      " [   1    0    4   29   21]\n",
      " [   1    1   12   66   80]\n",
      " [   0    0   11  140  344]\n",
      " [   0    0    7  267 1778]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.03      0.06        60\n",
      "           2       0.00      0.00      0.00        55\n",
      "           3       0.32      0.07      0.12       160\n",
      "           4       0.27      0.28      0.28       495\n",
      "           5       0.79      0.87      0.82      2052\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2822\n",
      "   macro avg       0.37      0.25      0.26      2822\n",
      "weighted avg       0.65      0.68      0.66      2822\n",
      "\n",
      "duration of this fold:  0:00:48.292374\n",
      "[[   5    2    2   19   32]\n",
      " [   1    0    2   20   32]\n",
      " [   0    1    7   75   77]\n",
      " [   0    0    6  162  327]\n",
      " [   0    0   10  333 1709]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.08      0.15        60\n",
      "           2       0.00      0.00      0.00        55\n",
      "           3       0.26      0.04      0.07       160\n",
      "           4       0.27      0.33      0.29       495\n",
      "           5       0.79      0.83      0.81      2052\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      2822\n",
      "   macro avg       0.43      0.26      0.27      2822\n",
      "weighted avg       0.65      0.67      0.65      2822\n",
      "\n",
      "duration of this fold:  0:00:48.025545\n",
      "[[   6    0    2   24   28]\n",
      " [   1    1    3   23   27]\n",
      " [   1    2    8   66   83]\n",
      " [   1    1    7  158  328]\n",
      " [   0    3   18  318 1712]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.10      0.17        60\n",
      "           2       0.14      0.02      0.03        55\n",
      "           3       0.21      0.05      0.08       160\n",
      "           4       0.27      0.32      0.29       495\n",
      "           5       0.79      0.83      0.81      2051\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      2821\n",
      "   macro avg       0.41      0.26      0.28      2821\n",
      "weighted avg       0.65      0.67      0.65      2821\n",
      "\n",
      "duration of this fold:  0:00:48.969006\n",
      "[[   6    0    1   23   30]\n",
      " [   3    0    3   22   26]\n",
      " [   0    3    8   69   80]\n",
      " [   0    1    7  145  341]\n",
      " [   1    0    8  289 1753]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.10      0.17        60\n",
      "           2       0.00      0.00      0.00        54\n",
      "           3       0.30      0.05      0.09       160\n",
      "           4       0.26      0.29      0.28       494\n",
      "           5       0.79      0.85      0.82      2051\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2819\n",
      "   macro avg       0.39      0.26      0.27      2819\n",
      "weighted avg       0.65      0.68      0.65      2819\n",
      "\n",
      "duration of this fold:  0:00:48.808098\n",
      "[[   8    1    5   21   25]\n",
      " [   2    1    1   20   30]\n",
      " [   2    2   10   59   86]\n",
      " [   0    0    5  139  350]\n",
      " [   1    0   10  282 1758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.13      0.22        60\n",
      "           2       0.25      0.02      0.03        54\n",
      "           3       0.32      0.06      0.11       159\n",
      "           4       0.27      0.28      0.27       494\n",
      "           5       0.78      0.86      0.82      2051\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2818\n",
      "   macro avg       0.45      0.27      0.29      2818\n",
      "weighted avg       0.65      0.68      0.65      2818\n",
      "\n",
      "duration of this fold:  0:00:51.849360\n",
      "[[   7    0    3   20   30]\n",
      " [   1    0    2   20   31]\n",
      " [   0    0   12   53   94]\n",
      " [   0    0   11  168  315]\n",
      " [   0    1   17  346 1687]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.12      0.21        60\n",
      "           2       0.00      0.00      0.00        54\n",
      "           3       0.27      0.08      0.12       159\n",
      "           4       0.28      0.34      0.31       494\n",
      "           5       0.78      0.82      0.80      2051\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      2818\n",
      "   macro avg       0.44      0.27      0.29      2818\n",
      "weighted avg       0.65      0.67      0.65      2818\n",
      "\n",
      "duration of this fold:  0:00:50.346220\n",
      "accuracy testing: 0.6742162922361638\n",
      "precision_micro: 0.6742162922361638\n",
      "recall_micro: 0.6742162922361638\n",
      "f1_micro: 0.6742162922361638\n",
      "\n",
      "precision_macro: 0.4529161392659051\n",
      "recall_macro: 0.26447248040366816\n",
      "f1_macro: 0.2772505784404673\n",
      "\n",
      "precision_weighted: 0.653120579395491\n",
      "recall_weighted: 0.6742162922361638\n",
      "f1_weighted: 0.6519594504923766\n",
      "duration of training:  0:08:28.577239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def train_model(X,Y):\n",
    "    \"\"\"\n",
    "    We will be experimenting on Support Vector Machine and Multilayer Perceptron Neural Network \n",
    "    to determine which algorithm builds a better model. We will also perform both oversampling(ADASYN)\n",
    "    and undersampling (NearMiss) to determine which resampling method is more accurate. Besides that, \n",
    "    we will be using SelectKBest method to select features. We will be testing out OneVsRestClassifier\n",
    "    on SVC models to see whether it improves the accuracy and precision values. The usage of pipeline is\n",
    "    to prevent any data leakage.\n",
    "    \n",
    "    Some lines of code for LinearSVC, SVC and MLP are commented out to prevent confusion. \n",
    "    To test out a specific line of code, comment out the current line of code and uncomment the you want to try.\n",
    "    To run the code without feature selection, remove SelectKBest() from the respective line of code.\n",
    "    \n",
    "    :params X: the tfidf values to be trained\n",
    "    :params Y: the ratings to be trained\n",
    "    \"\"\"\n",
    "    accuracy = []\n",
    "    precision_micro = []\n",
    "    recall_micro = []\n",
    "    f1_micro =[]\n",
    "    precision_macro = []\n",
    "    recall_macro = []\n",
    "    f1_macro =[]\n",
    "    precision_weighted = []\n",
    "    recall_weighted = []\n",
    "    f1_weighted =[]\n",
    "    \n",
    "    #using stratified kfold to split the data into 10 folds\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=42, shuffle = False)\n",
    "    \n",
    "    for train_index, test_index in cv.split(X,Y):\n",
    "        start_fold = datetime.datetime.now()\n",
    "        \n",
    "        #setting the training and testing data\n",
    "        X_train,X_test = X[train_index],X[test_index]\n",
    "        y_train,y_test = Y[train_index],Y[test_index]\n",
    "        \n",
    "        ''' SVC\n",
    "        For our research, we switched the kernel between 'rbf' and 'linear' with different numbers of features selected.\n",
    "        The first and second line of code performs oversampling whereas the third and fourth line of code performs undersampling.\n",
    "        The first and third line of code contains OneVsRestClassifier whereas the second and fourth line of code does not.\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),ADASYN(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),ADASYN(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),NearMiss(),OneVsRestClassifier(SVC(kernel='rbf',gamma='auto',cache_size=1000)))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),NearMiss(),SVC(kernel='rbf',gamma='auto',cache_size=1000))\n",
    "        \n",
    "        ''' LinearSVC\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling\n",
    "        '''\n",
    "        pipeline = make_pipeline(SelectKBest(chi2, k=50000),ADASYN(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),NearMiss(),LinearSVC(C=1,max_iter=10000,random_state=42))\n",
    "        \n",
    "        ''' MLPClassifier\n",
    "        For our research, we switched the solver parameter between 'sgd' and 'adam' and tried different values of hidden_layer_sizes.\n",
    "        The first line of code performs oversampling whereas the second line of code performs undersampling\n",
    "        '''\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),ADASYN(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        #pipeline = make_pipeline(SelectKBest(chi2, k=50000),NearMiss(),MLPClassifier(solver='sgd', hidden_layer_sizes= (5,5), max_iter=1000,random_state=1))\n",
    "        \n",
    "        #fit the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        #using testing data to predict the results\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        #prints the confusion matrix\n",
    "        print(confusion_matrix(y_test,y_pred)) \n",
    "        #prints the classification report\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        \n",
    "        #appends the results into respective lists\n",
    "        accuracy.append(accuracy_score(y_test,y_pred))\n",
    "        #micro average\n",
    "        precision_micro.append(precision_score(y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        recall_micro.append(recall_score(y_test,y_pred,average='micro'))\n",
    "        f1_micro.append(f1_score(y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        #macro average\n",
    "        precision_macro.append(precision_score(y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        recall_macro.append(recall_score(y_test,y_pred,average='macro'))\n",
    "        f1_macro.append(f1_score(y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        #weighted average\n",
    "        precision_weighted.append(precision_score(y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        recall_weighted.append(recall_score(y_test,y_pred,average='weighted'))\n",
    "        f1_weighted.append(f1_score(y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        \n",
    "        print(\"duration for this fold: \",datetime.datetime.now() - start_fold)\n",
    "\n",
    "    #prints out the mean of the result from respective lists    \n",
    "    print(\"accuracy testing: {}\".format(np.mean(accuracy)))\n",
    "    print(\"precision_micro: {}\".format(np.mean(precision_micro)))\n",
    "    print(\"recall_micro: {}\".format(np.mean(recall_micro)))\n",
    "    print(\"f1_micro: {}\".format(np.mean(f1_micro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_macro: {}\".format(np.mean(precision_macro)))\n",
    "    print(\"recall_macro: {}\".format(np.mean(recall_macro)))\n",
    "    print(\"f1_macro: {}\".format(np.mean(f1_macro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_weighted: {}\".format(np.mean(precision_weighted)))\n",
    "    print(\"recall_weighted: {}\".format(np.mean(recall_weighted)))\n",
    "    print(\"f1_weighted: {}\".format(np.mean(f1_weighted)))\n",
    "    \n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "train_model(X_1,Y_train_1)\n",
    "end = datetime.datetime.now()\n",
    "duration = end - start\n",
    "print(\"duration of training: \",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
