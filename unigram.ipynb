{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                            # to analyse data that are stored in a csv file\n",
    "import numpy as np                             # to provide a large set of numeric datatypes that can be used to construct arrays\n",
    "import nltk                                    # a platform for building Python programs to work with human language data\n",
    "from nltk.corpus import stopwords              # to remove stopwords\n",
    "from nltk.stem import WordNetLemmatizer        # to lemmatize\n",
    "from nltk.corpus import wordnet                # used to check whether the word is an adjective, noun, verb or adverb\n",
    "import re   # regex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('review_ver2.csv')\n",
    "dat['processed'] = np.nan\n",
    "dat = dat.drop(columns = ['Unnamed: 0'])      # drop unnecessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"    \n",
    "    This function gets the wordnet postag of each words.\n",
    "    :param word: word in each review texts\n",
    "    :returns: the postag of each word \n",
    "    \"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))     # define the stop words\n",
    "lemmatizer = WordNetLemmatizer()                 # define the lemmatizer\n",
    "def preprocess(review):\n",
    "    \"\"\"\n",
    "    This function takes in a series object and \n",
    "    preprocess accordingly. \n",
    "    :param review: series object\n",
    "    :returns: preprocessed words\n",
    "    \"\"\"\n",
    "    result = review.str.replace(r'\\d+', '')     # Remove numbers/ digits\n",
    "    result = result.str.replace(r'\\W', ' ')     # Remove puntuations\n",
    "    val = result.str.lower()                    # Convert all the reviews to lowercase \n",
    "    \n",
    "    return val.apply(lambda row: [word for word in row.split() if word not in stop_words])   # tokenize and stop words removal\n",
    "    \n",
    "    \n",
    "def lemmatize_it(series_list):\n",
    "    \"\"\"\n",
    "    This function is to carry out lemmatization on the\n",
    "    tokenized review\n",
    "    :series_list: series object that contains token to be lemmatized\n",
    "    :returns: lemmatized word\n",
    "    \"\"\"\n",
    "    stem_it = []\n",
    "    for i in series_list:\n",
    "        lem = lemmatizer.lemmatize(i, get_wordnet_pos(i))    # lemmatize based on the POS tag\n",
    "        stem_it.append(lem)\n",
    "        \n",
    "    return stem_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part', 'magic', 'grow', 'boy', 'buy', 'give', 'new', 'hornby', 'catalogue', 'every', 'year', 'even', 'include', 'product', 'previous', 'year', 'still', 'get', 'old', 'one', 'date', 'back', 'somewhere', 'day', 'catalogue', 'especially', 'informative', 'tell', 'vintage', 'roll', 'stock', 'useful', 'dedicate', 'railway', 'one', 'particular', 'era', 'train', 'company']\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing \n",
    "dat['processed'] = preprocess(dat['review'])\n",
    "dat['processed'] = dat['processed'].apply(lemmatize_it)\n",
    "print(dat['processed'][0])    # to make sure the result is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28212, 18905)\n"
     ]
    }
   ],
   "source": [
    "# tf-idf using built-in function\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_1 = dat['processed'].values\n",
    "Y_1 = dat['rating'].values\n",
    "\n",
    "def dummy_func(docs):\n",
    "    \"\"\"\n",
    "    Works as a dummy function as the name implies\n",
    "    \"\"\"\n",
    "    return docs\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',tokenizer=dummy_func, preprocessor=dummy_func, token_pattern=None)\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(vectorizer.fit_transform(X_1))    # do tfidf transformer after tfidf vectorizer\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "corpus_index = [n for n in range(len(X_1))]\n",
    "rows, cols = X.nonzero()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train model with kfold cross-validation\n",
    "After getting the tfidf for each review, do kfold, undersample/ oversample\n",
    "and pass the result into the model for training\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold         # to perform kfold cross validation\n",
    "from imblearn.under_sampling import NearMiss                # to perform undersampling\n",
    "from imblearn.over_sampling import ADASYN                   # to perform oversampling\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score # score for evalution purposes\n",
    "from sklearn.neural_network import MLPClassifier            # to train with MLP classifier\n",
    "import time                                                 # to keep track of the time for program to execute\n",
    "from sklearn import svm                                     # to train with SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# list declaration\n",
    "Y = Y_1\n",
    "accuracy = []\n",
    "precision_micro = []\n",
    "recall_micro = []\n",
    "f1_micro =[]\n",
    "precision_macro = []\n",
    "recall_macro = []\n",
    "f1_macro =[]\n",
    "precision_weighted = []\n",
    "recall_weighted = []\n",
    "f1_weighted =[]\n",
    "\n",
    "def train_model(X, Y):\n",
    "    \"\"\"\n",
    "    We will be experimenting on Support Vector Machine and Multilayer Perceptron Neural Network \n",
    "    to determine which algorithm builds a better model. We will also perform both oversampling(ADASYN)\n",
    "    and undersampling (NearMiss) to determine which resampling method is more accurate. \n",
    "    \n",
    "    Some lines of code for LinearSVC, MLP are commented out to prevent confusion. \n",
    "    \n",
    "    :params X: the tfidf values to be trained\n",
    "    :params Y: the ratings to be trained\n",
    "    \"\"\"\n",
    "    # k fold cross validation\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        \"\"\"\n",
    "        # Do undersampling for training data\n",
    "        start = time.time()\n",
    "        nm = NearMiss()\n",
    "        X_res, Y_res = nm.fit_resample(X_train, Y_train)\n",
    "        done = time.time()\n",
    "        elapsed = done - start\n",
    "        print(\"Undersampling: \",elapsed)\n",
    "        print(len(Y_res))\n",
    "        \"\"\"\n",
    "\n",
    "        # Do oversampling for training data\n",
    "        start = time.time()\n",
    "        ada = ADASYN(random_state = 4, sampling_strategy='auto')\n",
    "        X_res, Y_res = ada.fit_resample(X_train, Y_train)\n",
    "        done = time.time()\n",
    "        elapsed = done - start\n",
    "        print(\"Oversampling: \",elapsed)\n",
    "        print(len(Y_res))\n",
    "\n",
    "        \"\"\"\n",
    "        # Do Linear SVC\n",
    "        \"\"\"\n",
    "        start1 = time.time()\n",
    "        classifier = svm.LinearSVC()\n",
    "        classifier.fit(X_res, Y_res) \n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        \"\"\"\n",
    "        # Do MLP\n",
    "        start1 = time.time()\n",
    "        mlp = MLPClassifier(solver='sgd', hidden_layer_sizes= (3,2), random_state=1, max_iter = 1000)\n",
    "        mlp.fit(X_res, y_res)\n",
    "        y_pred = mlp.predict(X_test)\n",
    "        \"\"\"\n",
    "        \n",
    "        print(confusion_matrix(Y_test, y_pred))\n",
    "        print(classification_report(Y_test,y_pred))\n",
    "\n",
    "        #appends the results into respective lists\n",
    "        accuracy.append(accuracy_score(Y_test,y_pred))\n",
    "        #micro average\n",
    "        precision_micro.append(precision_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        recall_micro.append(recall_score(Y_test,y_pred,average='micro'))\n",
    "        f1_micro.append(f1_score(Y_test,y_pred,average='micro',labels=np.unique(y_pred)))\n",
    "        #macro average\n",
    "        precision_macro.append(precision_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        recall_macro.append(recall_score(Y_test,y_pred,average='macro'))\n",
    "        f1_macro.append(f1_score(Y_test,y_pred,average='macro',labels=np.unique(y_pred)))\n",
    "        #weighted average\n",
    "        precision_weighted.append(precision_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        recall_weighted.append(recall_score(Y_test,y_pred,average='weighted'))\n",
    "        f1_weighted.append(f1_score(Y_test,y_pred,average='weighted',labels=np.unique(y_pred)))\n",
    "        \n",
    "        done1 = time.time()\n",
    "        elapsed1 = done1 - start1\n",
    "        print(\"Linear SVM: \", elapsed1)\n",
    "        \n",
    "    # prints out the mean of the result from respective lists    \n",
    "    print(\"accuracy testing: {}\".format(np.mean(accuracy)))\n",
    "    print(\"precision_micro: {}\".format(np.mean(precision_micro)))\n",
    "    print(\"recall_micro: {}\".format(np.mean(recall_micro)))\n",
    "    print(\"f1_micro: {}\".format(np.mean(f1_micro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_macro: {}\".format(np.mean(precision_macro)))\n",
    "    print(\"recall_macro: {}\".format(np.mean(recall_macro)))\n",
    "    print(\"f1_macro: {}\".format(np.mean(f1_macro)))\n",
    "    print(\"\")\n",
    "    print(\"precision_weighted: {}\".format(np.mean(precision_weighted)))\n",
    "    print(\"recall_weighted: {}\".format(np.mean(recall_weighted)))\n",
    "    print(\"f1_weighted: {}\".format(np.mean(f1_weighted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2762  2763  2765 ... 28209 28210 28211] TEST: [   0    1    2 ... 3282 3295 3307]\n",
      "Oversampling:  37.185096740722656\n",
      "91256\n",
      "[[  15    8   15   10   13]\n",
      " [   5    7   14   13   16]\n",
      " [   7   11   57   42   43]\n",
      " [   7   12   65  196  215]\n",
      " [  16   27  127  452 1430]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.25      0.27        61\n",
      "           2       0.11      0.13      0.12        55\n",
      "           3       0.21      0.36      0.26       160\n",
      "           4       0.27      0.40      0.32       495\n",
      "           5       0.83      0.70      0.76      2052\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      2823\n",
      "   macro avg       0.34      0.36      0.35      2823\n",
      "weighted avg       0.67      0.60      0.63      2823\n",
      "\n",
      "Linear SVM:  4.822035789489746\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [2762 2763 2765 ... 5803 5804 5820]\n",
      "Oversampling:  36.0153603553772\n",
      "91239\n",
      "[[  23    6   16    8    8]\n",
      " [   9    3   17   14   12]\n",
      " [  20    4   67   42   27]\n",
      " [  25   18   88  157  207]\n",
      " [  62   42  171  416 1361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.38      0.23        61\n",
      "           2       0.04      0.05      0.05        55\n",
      "           3       0.19      0.42      0.26       160\n",
      "           4       0.25      0.32      0.28       495\n",
      "           5       0.84      0.66      0.74      2052\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2823\n",
      "   macro avg       0.30      0.37      0.31      2823\n",
      "weighted avg       0.67      0.57      0.61      2823\n",
      "\n",
      "Linear SVM:  4.959915637969971\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [4726 4748 4751 ... 8682 8686 8687]\n",
      "Oversampling:  37.51749324798584\n",
      "91022\n",
      "[[  15   10   12   14   10]\n",
      " [   7    6   13   14   15]\n",
      " [  10   12   50   53   35]\n",
      " [  17   12   75  155  236]\n",
      " [  35   29  132  444 1412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.18      0.25      0.21        61\n",
      "           2       0.09      0.11      0.10        55\n",
      "           3       0.18      0.31      0.23       160\n",
      "           4       0.23      0.31      0.26       495\n",
      "           5       0.83      0.69      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.30      0.33      0.31      2823\n",
      "weighted avg       0.66      0.58      0.61      2823\n",
      "\n",
      "Linear SVM:  4.935524225234985\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [ 6460  6511  6515 ... 11580 11583 11595]\n",
      "Oversampling:  36.97108697891235\n",
      "91162\n",
      "[[  16    9   12   10   14]\n",
      " [  12   14   13    8    8]\n",
      " [  12   16   36   52   44]\n",
      " [  11   18   90  168  208]\n",
      " [  29   37  132  455 1399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.26      0.23        61\n",
      "           2       0.15      0.25      0.19        55\n",
      "           3       0.13      0.23      0.16       160\n",
      "           4       0.24      0.34      0.28       495\n",
      "           5       0.84      0.68      0.75      2052\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2823\n",
      "   macro avg       0.31      0.35      0.32      2823\n",
      "weighted avg       0.66      0.58      0.61      2823\n",
      "\n",
      "Linear SVM:  4.7512547969818115\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [ 9358  9390  9420 ... 14553 14558 14589]\n",
      "Oversampling:  35.076398849487305\n",
      "91162\n",
      "[[  15    4   18   10   13]\n",
      " [  10    5   16   17    7]\n",
      " [  14   13   47   58   28]\n",
      " [   6    9   60  168  252]\n",
      " [  19   19   96  379 1539]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.25      0.24        60\n",
      "           2       0.10      0.09      0.10        55\n",
      "           3       0.20      0.29      0.24       160\n",
      "           4       0.27      0.34      0.30       495\n",
      "           5       0.84      0.75      0.79      2052\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      2822\n",
      "   macro avg       0.33      0.34      0.33      2822\n",
      "weighted avg       0.67      0.63      0.65      2822\n",
      "\n",
      "Linear SVM:  4.793972015380859\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [13042 13109 13246 ... 17234 17235 17237]\n",
      "Oversampling:  36.64621305465698\n",
      "91063\n",
      "[[  14    9    9   20    8]\n",
      " [   7    5   16   17   10]\n",
      " [   6   15   46   57   36]\n",
      " [   8   19   69  155  244]\n",
      " [  18   24   99  527 1384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.23      0.25        60\n",
      "           2       0.07      0.09      0.08        55\n",
      "           3       0.19      0.29      0.23       160\n",
      "           4       0.20      0.31      0.24       495\n",
      "           5       0.82      0.67      0.74      2052\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      2822\n",
      "   macro avg       0.31      0.32      0.31      2822\n",
      "weighted avg       0.65      0.57      0.60      2822\n",
      "\n",
      "Linear SVM:  4.820040941238403\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [16683 16734 16760 ... 20128 20129 20138]\n",
      "Oversampling:  37.49285864830017\n",
      "90788\n",
      "[[  19    7   17    8    9]\n",
      " [   9    9   16   11   10]\n",
      " [   5    7   43   54   51]\n",
      " [   9   17   83  152  234]\n",
      " [  21   27  117  465 1421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.32      0.31        60\n",
      "           2       0.13      0.16      0.15        55\n",
      "           3       0.16      0.27      0.20       160\n",
      "           4       0.22      0.31      0.26       495\n",
      "           5       0.82      0.69      0.75      2051\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2821\n",
      "   macro avg       0.33      0.35      0.33      2821\n",
      "weighted avg       0.66      0.58      0.61      2821\n",
      "\n",
      "Linear SVM:  4.966349363327026\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [19326 19399 19400 ... 22904 22925 22928]\n",
      "Oversampling:  37.26031303405762\n",
      "90811\n",
      "[[  15    3   20   15    7]\n",
      " [  15    4   11   13   11]\n",
      " [   6   10   43   60   41]\n",
      " [  10   14   65  185  220]\n",
      " [  13   25  115  590 1308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.25      0.25        60\n",
      "           2       0.07      0.07      0.07        54\n",
      "           3       0.17      0.27      0.21       160\n",
      "           4       0.21      0.37      0.27       494\n",
      "           5       0.82      0.64      0.72      2051\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      2819\n",
      "   macro avg       0.31      0.32      0.30      2819\n",
      "weighted avg       0.65      0.55      0.59      2819\n",
      "\n",
      "Linear SVM:  4.715911388397217\n",
      "TRAIN: [    0     1     2 ... 28209 28210 28211] TEST: [22485 22486 22487 ... 25925 25947 25969]\n",
      "Oversampling:  36.294347286224365\n",
      "90880\n",
      "[[  22   14   11    9    4]\n",
      " [   9    4   16   14   11]\n",
      " [   7   12   47   55   38]\n",
      " [   5   11   69  181  228]\n",
      " [  17   13  123  520 1378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.37      0.37        60\n",
      "           2       0.07      0.07      0.07        54\n",
      "           3       0.18      0.30      0.22       159\n",
      "           4       0.23      0.37      0.28       494\n",
      "           5       0.83      0.67      0.74      2051\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      2818\n",
      "   macro avg       0.34      0.35      0.34      2818\n",
      "weighted avg       0.66      0.58      0.61      2818\n",
      "\n",
      "Linear SVM:  4.71564507484436\n",
      "TRAIN: [    0     1     2 ... 25925 25947 25969] TEST: [25212 25214 25215 ... 28209 28210 28211]\n",
      "Oversampling:  34.8230926990509\n",
      "90784\n",
      "[[  19    7    8   16   10]\n",
      " [   7    6   14   16   11]\n",
      " [   7    8   53   58   33]\n",
      " [   6    9   70  165  244]\n",
      " [  13   21  119  473 1425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.32      0.34        60\n",
      "           2       0.12      0.11      0.11        54\n",
      "           3       0.20      0.33      0.25       159\n",
      "           4       0.23      0.33      0.27       494\n",
      "           5       0.83      0.69      0.76      2051\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      2818\n",
      "   macro avg       0.35      0.36      0.35      2818\n",
      "weighted avg       0.66      0.59      0.62      2818\n",
      "\n",
      "Linear SVM:  4.540679454803467\n",
      "accuracy testing: 0.583578612829496\n",
      "precision_micro: 0.583578612829496\n",
      "recall_micro: 0.583578612829496\n",
      "f1_micro: 0.583578612829496\n",
      "\n",
      "precision_macro: 0.32052625415541175\n",
      "recall_macro: 0.3465337130288307\n",
      "f1_macro: 0.32505274752744634\n",
      "\n",
      "precision_weighted: 0.662690699780961\n",
      "recall_weighted: 0.583578612829496\n",
      "f1_weighted: 0.6149529541831369\n"
     ]
    }
   ],
   "source": [
    "# To train the data\n",
    "train_model(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
